{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Files\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nimport glob\nimport pickle\n\n#DATA\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import one_hot\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.image as mpimg\n\n#CNN\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.applications.vgg16 import VGG16\n\n#VIS\nfrom keras.utils.vis_utils import plot_model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-18T10:39:19.770526Z","iopub.execute_input":"2022-01-18T10:39:19.770998Z","iopub.status.idle":"2022-01-18T10:39:26.896307Z","shell.execute_reply.started":"2022-01-18T10:39:19.770907Z","shell.execute_reply":"2022-01-18T10:39:26.895309Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def _prepareData(path): \n    '''\n    params: path(string)\n    return: [list list] of images in dataset and the list of labels\n    '''\n    labelsList = []\n    listOfimg = []\n    for directory in sorted(glob.glob(os.path.join(path, '*')), key = lambda k: k.split(\"/\")[-1]):\n            for img in glob.glob(os.path.join(directory,'*.jpg')):\n                imgcv = cv2.imread(img)\n                imgcv_r = cv2.resize(imgcv,(224,224)) #Resize to 128,128\n                listOfimg.append(imgcv_r)\n                labelsList.append(int(directory.split(\"/\")[-1].replace('c','')))\n    \n    X_Train, X_Test, Y_Train, Y_Test =  train_test_split(listOfimg,labelsList, test_size = 0.2)\n    Y_Train = tf.keras.utils.to_categorical(Y_Train, num_classes=10)\n    Y_Test = tf.keras.utils.to_categorical(Y_Test, num_classes=10)\n\n    return np.array(X_Train), np.array(X_Test), Y_Train, Y_Test","metadata":{"execution":{"iopub.status.busy":"2022-01-18T10:40:05.023419Z","iopub.execute_input":"2022-01-18T10:40:05.023763Z","iopub.status.idle":"2022-01-18T10:40:05.034165Z","shell.execute_reply.started":"2022-01-18T10:40:05.023717Z","shell.execute_reply":"2022-01-18T10:40:05.032715Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"'''#Paths\npathTrainImages = \"/kaggle/input/state-farm-distracted-driver-detection/img/train/\"\npathPropagateImages =  \"/kaggle/input/state-farm-distracted-driver-detection/img/test/\"\n\n#List of Images for Train and Test\nX_Train, X_Test, Y_Train, Y_Test = _prepareData(pathTrainImages)\n\nprint(\"Size X_Train: {}, Size Y_Train: {}\".format(len(X_Train),len(Y_Train)))\nprint(\"Size X_Test: {}, Size Y_Test: {}\".format(len(X_Test),len(Y_Test)))\n'''\n#Paths\npathTrain_Images = \"/kaggle/input/state-farm-distracted-driver-detection/imgs/train/\"\npathPropagate_Images =  \"/kaggle/input/state-farm-distracted-driver-detection/imgs/test/\"\n\n#List of Images for Train and Test\nX_Train, X_Test, Y_Train, Y_Test = _prepareData(pathTrain_Images)\n\nprint(\"Size X_Train: {}, Size Y_Train: {}\".format(len(X_Train),len(Y_Train)))\nprint(\"Size X_Test: {}, Size Y_Test: {}\".format(len(X_Test),len(Y_Test)))","metadata":{"execution":{"iopub.status.busy":"2022-01-18T10:40:05.387108Z","iopub.execute_input":"2022-01-18T10:40:05.387368Z","iopub.status.idle":"2022-01-18T10:44:19.274367Z","shell.execute_reply.started":"2022-01-18T10:40:05.387339Z","shell.execute_reply":"2022-01-18T10:44:19.273326Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def vgg(input_shape, num_classes, mode):\n    vgg = VGG16(\n        include_top=False, weights='imagenet', input_tensor=None,\n        input_shape=input_shape, pooling=None, classes=num_classes,\n        classifier_activation='softmax'\n        )\n    if mode=='feature-extraction':\n        vgg.trainable = False\n    if mode=='fine-tune':\n        vgg.trainable = True\n        # Let's take a look to see how many layers are in the base model\n        print(\"Number of layers in the base model: \", len(vgg.layers))\n\n        # Fine-tune from this layer onwards\n        fine_tune_at = 10\n\n        # Freeze all the layers before the `fine_tune_at` layer\n        for layer in vgg.layers[:fine_tune_at]:\n            layer.trainable =  False\n    print(vgg.summary())\n    return vgg","metadata":{"execution":{"iopub.status.busy":"2022-01-18T10:44:25.626688Z","iopub.execute_input":"2022-01-18T10:44:25.626964Z","iopub.status.idle":"2022-01-18T10:44:25.633989Z","shell.execute_reply.started":"2022-01-18T10:44:25.626935Z","shell.execute_reply":"2022-01-18T10:44:25.632913Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def transfer_learn(base_model, input_shape, num_classes):\n    inputs = tf.keras.Input(shape=input_shape)\n#     x = utils.augment_data(inputs)\n    x = preprocess_input(inputs)\n    x = base_model(x, training=False)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n    outputs = tf.keras.layers.Dense(num_classes)(x)\n    model = tf.keras.Model(inputs, outputs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-18T10:44:25.935974Z","iopub.execute_input":"2022-01-18T10:44:25.936246Z","iopub.status.idle":"2022-01-18T10:44:25.944895Z","shell.execute_reply.started":"2022-01-18T10:44:25.936216Z","shell.execute_reply":"2022-01-18T10:44:25.943634Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"NUM_CLASSES = 10\nLEARNING_RATE = 0.001\nNUM_EPOCHS = 10\nINPUT_SHAPE = (224,224,3)\n# weights_path = os.path.join(utils.BASE_PATH, 'weights/')\n# history_path = os.path.join(utils.BASE_PATH, 'history/')\ndef compile_model(model, learning_rate):\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n                metrics=['accuracy'])\n    print(model.summary())\n    return model\n\n\ndef fit_model(model, initial_epochs, train_data, train_labels):\n    history = model.fit(x = train_data, y = train_labels,\n                        epochs = initial_epochs, batch_size = 8,\n                        verbose = 1,validation_split=0.2)\n    return history\n\n# def save_weights(model, name):\n#     model.save(weights_path+name+\".h5\")\n\n# def save_history(history, file_name):\n#     with open(file_name, 'wb') as file_p:\n#         pickle.dump(history.history, file_p)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T10:48:29.313347Z","iopub.execute_input":"2022-01-18T10:48:29.313642Z","iopub.status.idle":"2022-01-18T10:48:29.323865Z","shell.execute_reply.started":"2022-01-18T10:48:29.313613Z","shell.execute_reply":"2022-01-18T10:48:29.322227Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"fine_tune_epochs = 10\ntotal_epochs =  NUM_EPOCHS + fine_tune_epochs\nvgg16_fine = vgg(INPUT_SHAPE, NUM_CLASSES, 'fine-tune')\nfine_model = compile_model(transfer_learn(vgg16_fine, INPUT_SHAPE, NUM_CLASSES), LEARNING_RATE)\nhistory = fit_model(fine_model, total_epochs, X_Train, Y_Train)\n# save_weights(fine_model, 'fineTune')\n# save_history(fine_history, history_path+'fineTune')","metadata":{"execution":{"iopub.status.busy":"2022-01-18T10:48:30.172827Z","iopub.execute_input":"2022-01-18T10:48:30.173273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\n\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\n#plt.ylim([0.9,1])\nplt.legend(['train','test'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\n\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\n#plt.ylim([0,.4])\nplt.legend(['train','test'], loc='upper left')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}