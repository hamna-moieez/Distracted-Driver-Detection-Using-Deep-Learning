{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Files\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nimport glob\nimport pickle\n\n#DATA\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import one_hot\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.image as mpimg\n\n#CNN\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.applications.vgg16 import VGG16\n\n#VIS\nfrom keras.utils.vis_utils import plot_model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-18T12:57:02.661460Z","iopub.execute_input":"2022-01-18T12:57:02.661930Z","iopub.status.idle":"2022-01-18T12:57:08.629938Z","shell.execute_reply.started":"2022-01-18T12:57:02.661797Z","shell.execute_reply":"2022-01-18T12:57:08.628902Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def _prepareData(path): \n    '''\n    params: path(string)\n    return: [list list] of images in dataset and the list of labels\n    '''\n    labelsList = []\n    listOfimg = []\n    for directory in sorted(glob.glob(os.path.join(path, '*')), key = lambda k: k.split(\"/\")[-1]):\n            for img in glob.glob(os.path.join(directory,'*.jpg')):\n                imgcv = cv2.imread(img)\n                imgcv_r = cv2.resize(imgcv,(224,224)) #Resize to 128,128\n                listOfimg.append(imgcv_r)\n                labelsList.append(int(directory.split(\"/\")[-1].replace('c','')))\n    \n    X_Train, X_Test, Y_Train, Y_Test =  train_test_split(listOfimg,labelsList, test_size = 0.2)\n    Y_Train = tf.keras.utils.to_categorical(Y_Train, num_classes=10)\n    Y_Test = tf.keras.utils.to_categorical(Y_Test, num_classes=10)\n\n    return np.array(X_Train), np.array(X_Test), Y_Train, Y_Test","metadata":{"execution":{"iopub.status.busy":"2022-01-18T12:57:08.633379Z","iopub.execute_input":"2022-01-18T12:57:08.634014Z","iopub.status.idle":"2022-01-18T12:57:08.643440Z","shell.execute_reply.started":"2022-01-18T12:57:08.633979Z","shell.execute_reply":"2022-01-18T12:57:08.642214Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"'''#Paths\npathTrainImages = \"/kaggle/input/state-farm-distracted-driver-detection/img/train/\"\npathPropagateImages =  \"/kaggle/input/state-farm-distracted-driver-detection/img/test/\"\n\n#List of Images for Train and Test\nX_Train, X_Test, Y_Train, Y_Test = _prepareData(pathTrainImages)\n\nprint(\"Size X_Train: {}, Size Y_Train: {}\".format(len(X_Train),len(Y_Train)))\nprint(\"Size X_Test: {}, Size Y_Test: {}\".format(len(X_Test),len(Y_Test)))\n'''\n#Paths\npathTrain_Images = \"/kaggle/input/state-farm-distracted-driver-detection/imgs/train/\"\npathPropagate_Images =  \"/kaggle/input/state-farm-distracted-driver-detection/imgs/test/\"\n\n#List of Images for Train and Test\nX_Train, X_Test, Y_Train, Y_Test = _prepareData(pathTrain_Images)\n\nprint(\"Size X_Train: {}, Size Y_Train: {}\".format(len(X_Train),len(Y_Train)))\nprint(\"Size X_Test: {}, Size Y_Test: {}\".format(len(X_Test),len(Y_Test)))","metadata":{"execution":{"iopub.status.busy":"2022-01-18T12:57:08.645574Z","iopub.execute_input":"2022-01-18T12:57:08.646285Z","iopub.status.idle":"2022-01-18T13:01:22.647327Z","shell.execute_reply.started":"2022-01-18T12:57:08.646239Z","shell.execute_reply":"2022-01-18T13:01:22.646278Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"NUM_CLASSES = 10\nLEARNING_RATE = 0.0001\nNUM_EPOCHS = 10\nBATCH_SIZE = 16\nINPUT_SHAPE = (224,224,3)\n\ndef compile_model(model, learning_rate):\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n                metrics=['accuracy'])\n    print(model.summary())\n    return model\n\n\ndef fit_model(model, initial_epochs, batch_size, train_data, train_labels):\n    history = model.fit(x = train_data, y = train_labels,\n                        epochs = initial_epochs, batch_size = batch_size,\n                        verbose = 1,validation_split=0.2)\n    return history\n\ndef plot_accuracy(history, model_name):\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n\n    plt.title(model_name+' Accuray')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    #plt.ylim([0.9,1])\n    plt.legend(['train','test'], loc='upper left')\n    plt.show()\n    \ndef plot_loss(history, model_name):\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n\n    plt.title(model_name+' Loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    #plt.ylim([0,.4])\n    plt.legend(['train','test'], loc='upper left')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-18T13:01:42.201245Z","iopub.execute_input":"2022-01-18T13:01:42.202183Z","iopub.status.idle":"2022-01-18T13:01:42.217245Z","shell.execute_reply.started":"2022-01-18T13:01:42.202126Z","shell.execute_reply":"2022-01-18T13:01:42.215946Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# CNN","metadata":{}},{"cell_type":"markdown","source":"We create our own customized CNN model using the standard CNN architecture Conv => Activation => MaxPool","metadata":{}},{"cell_type":"code","source":"def create_model(input_shape, num_classes):\n    model = tf.keras.Sequential([\n    tf.keras.Input(shape=input_shape),\n    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n    tf.keras.layers.MaxPooling2D(),\n    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n    tf.keras.layers.MaxPooling2D(),\n    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n    tf.keras.layers.MaxPooling2D(),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(num_classes)\n    ])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-18T13:01:43.340232Z","iopub.execute_input":"2022-01-18T13:01:43.341120Z","iopub.status.idle":"2022-01-18T13:01:43.351059Z","shell.execute_reply.started":"2022-01-18T13:01:43.341074Z","shell.execute_reply":"2022-01-18T13:01:43.349664Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Next, we introduce data augmentation layer and normalization layer into the previously built CNN","metadata":{}},{"cell_type":"code","source":"def create_augmented(input_shape, num_classes):\n    model = tf.keras.Sequential([\n    tf.keras.Input(shape=input_shape),\n    tf.keras.layers.RandomFlip(\"horizontal\"), \n    tf.keras.layers.RandomRotation(0.1),\n    tf.keras.layers.Rescaling(1./255),\n    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n    tf.keras.layers.MaxPooling2D(),\n    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n    tf.keras.layers.MaxPooling2D(),\n    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n    tf.keras.layers.MaxPooling2D(),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(num_classes)\n    ])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-18T13:01:44.074411Z","iopub.execute_input":"2022-01-18T13:01:44.074698Z","iopub.status.idle":"2022-01-18T13:01:44.085025Z","shell.execute_reply.started":"2022-01-18T13:01:44.074666Z","shell.execute_reply":"2022-01-18T13:01:44.081925Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"custom = create_model(INPUT_SHAPE, NUM_CLASSES)\ncustom_model = compile_model(custom, LEARNING_RATE)\ncus_history = fit_model(custom_model, NUM_EPOCHS, BATCH_SIZE, X_Train, Y_Train)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T13:01:44.460720Z","iopub.execute_input":"2022-01-18T13:01:44.461165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(cus_history, 'Custom-CNN')\nplot_accuracy(cus_history, 'Custom-CNN')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_acc = custom_model.evaluate(X_Test, Y_Test, verbose = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_aug = create_augmented(INPUT_SHAPE, NUM_CLASSES)\ncustom_aug_model = compile_model(custom_aug, LEARNING_RATE)\naug_history = fit_model(custom_aug_model, NUM_EPOCHS, BATCH_SIZE, X_Train, Y_Train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(aug_history, 'Custom-Augmentation-CNN')\nplot_accuracy(aug_history, 'Custom-Augmentation-CNN')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_acc = custom_aug_model.evaluate(X_Test, Y_Test, verbose = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TRANSFER LEARNING\nNow, we build models using transfer learning approaches to improve results.","metadata":{}},{"cell_type":"code","source":"def vgg(input_shape, num_classes, mode):\n    vgg = VGG16(\n        include_top=False, weights='imagenet', input_tensor=None,\n        input_shape=input_shape, pooling=None, classes=num_classes,\n        classifier_activation='softmax'\n        )\n    if mode=='feature-extraction':\n        vgg.trainable = False\n    if mode=='fine-tune':\n        vgg.trainable = True\n        # Let's take a look to see how many layers are in the base model\n        print(\"Number of layers in the base model: \", len(vgg.layers))\n\n        # Fine-tune from this layer onwards\n        fine_tune_at = 16\n\n        # Freeze all the layers before the `fine_tune_at` layer\n        for layer in vgg.layers[:fine_tune_at]:\n            layer.trainable =  False\n    print(vgg.summary())\n    return vgg","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transfer_learn(base_model, input_shape, num_classes):\n    inputs = tf.keras.Input(shape=input_shape)\n#     x = utils.augment_data(inputs)\n    x = preprocess_input(inputs)\n    x = base_model(x, training=False)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n    outputs = tf.keras.layers.Dense(num_classes)(x)\n    model = tf.keras.Model(inputs, outputs)\n    return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Extraction\nExtracting bottleneck features from a pretrained VGG16","metadata":{}},{"cell_type":"code","source":"vgg16 = vgg(INPUT_SHAPE, NUM_CLASSES, 'feature-extraction')\nfe_model = compile_model(transfer_learn(vgg16, INPUT_SHAPE, NUM_CLASSES), LEARNING_RATE)\nfe_history = fit_model(fe_model, NUM_EPOCHS, BATCH_SIZE, X_Train, Y_Train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(fe_history, 'Feature-Extraction')\nplot_accuracy(fe_history, 'Feature-Extraction')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_acc = fe_model.evaluate(X_Test, Y_Test, verbose = 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fine Tuning\nFine tune some layers of the VGG16 i.e. retrain some the weights of the top layers of the pre-trained model alongside the training of the top that we previously trained to increase performance even further.","metadata":{}},{"cell_type":"code","source":"fine_tune_epochs = 10\ntotal_epochs =  NUM_EPOCHS + fine_tune_epochs\nvgg16_fine = vgg(INPUT_SHAPE, NUM_CLASSES, 'fine-tune')\nfine_model = compile_model(transfer_learn(vgg16_fine, INPUT_SHAPE, NUM_CLASSES), LEARNING_RATE)\nft_history = fit_model(fine_model, total_epochs, X_Train, Y_Train)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T12:30:26.521613Z","iopub.execute_input":"2022-01-18T12:30:26.522409Z","iopub.status.idle":"2022-01-18T12:49:53.608834Z","shell.execute_reply.started":"2022-01-18T12:30:26.522370Z","shell.execute_reply":"2022-01-18T12:49:53.607722Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"plot_loss(ft_history, 'Fine-Tuner')\nplot_accuracy(ft_history, 'Fine-Tuner')","metadata":{"execution":{"iopub.status.busy":"2022-01-18T12:49:53.611731Z","iopub.execute_input":"2022-01-18T12:49:53.612142Z","iopub.status.idle":"2022-01-18T12:49:54.101907Z","shell.execute_reply.started":"2022-01-18T12:49:53.612057Z","shell.execute_reply":"2022-01-18T12:49:54.100753Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"test_loss, test_acc = fine_model.evaluate(X_Test, Y_Test, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T12:49:54.103557Z","iopub.execute_input":"2022-01-18T12:49:54.104347Z","iopub.status.idle":"2022-01-18T12:50:05.494934Z","shell.execute_reply.started":"2022-01-18T12:49:54.104297Z","shell.execute_reply":"2022-01-18T12:50:05.493927Z"},"trusted":true},"execution_count":21,"outputs":[]}]}