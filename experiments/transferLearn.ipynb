{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Files\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nimport glob\nimport pickle\n\n#DATA\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import one_hot\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.image as mpimg\n\n#CNN\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.applications.vgg16 import VGG16\n\n#VIS\nfrom keras.utils.vis_utils import plot_model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-18T17:29:37.056599Z","iopub.execute_input":"2022-01-18T17:29:37.05705Z","iopub.status.idle":"2022-01-18T17:29:42.027067Z","shell.execute_reply.started":"2022-01-18T17:29:37.057011Z","shell.execute_reply":"2022-01-18T17:29:42.026205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _prepareData(path): \n    '''\n    params: path(string)\n    return: [list list] of images in dataset and the list of labels\n    '''\n    labelsList = []\n    listOfimg = []\n    for directory in sorted(glob.glob(os.path.join(path, '*')), key = lambda k: k.split(\"/\")[-1]):\n            for img in glob.glob(os.path.join(directory,'*.jpg')):\n                imgcv = cv2.imread(img)\n                imgcv_r = cv2.resize(imgcv,(224,224)) #Resize to 128,128\n                listOfimg.append(imgcv_r)\n                labelsList.append(int(directory.split(\"/\")[-1].replace('c','')))\n    \n    X_Train, X_Test, Y_Train, Y_Test =  train_test_split(listOfimg,labelsList, test_size = 0.2)\n    Y_Train = tf.keras.utils.to_categorical(Y_Train, num_classes=10)\n    Y_Test = tf.keras.utils.to_categorical(Y_Test, num_classes=10)\n\n    return np.array(X_Train), np.array(X_Test), Y_Train, Y_Test","metadata":{"execution":{"iopub.status.busy":"2022-01-18T17:29:42.028728Z","iopub.execute_input":"2022-01-18T17:29:42.029145Z","iopub.status.idle":"2022-01-18T17:29:42.038653Z","shell.execute_reply.started":"2022-01-18T17:29:42.029105Z","shell.execute_reply":"2022-01-18T17:29:42.037877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''#Paths\npathTrainImages = \"/kaggle/input/state-farm-distracted-driver-detection/img/train/\"\npathPropagateImages =  \"/kaggle/input/state-farm-distracted-driver-detection/img/test/\"\n\n#List of Images for Train and Test\nX_Train, X_Test, Y_Train, Y_Test = _prepareData(pathTrainImages)\n\nprint(\"Size X_Train: {}, Size Y_Train: {}\".format(len(X_Train),len(Y_Train)))\nprint(\"Size X_Test: {}, Size Y_Test: {}\".format(len(X_Test),len(Y_Test)))\n'''\n#Paths\npathTrain_Images = \"/kaggle/input/state-farm-distracted-driver-detection/imgs/train/\"\npathPropagate_Images =  \"/kaggle/input/state-farm-distracted-driver-detection/imgs/test/\"\n\n#List of Images for Train and Test\nX_Train, X_Test, Y_Train, Y_Test = _prepareData(pathTrain_Images)\n\nprint(\"Size X_Train: {}, Size Y_Train: {}\".format(len(X_Train),len(Y_Train)))\nprint(\"Size X_Test: {}, Size Y_Test: {}\".format(len(X_Test),len(Y_Test)))","metadata":{"execution":{"iopub.status.busy":"2022-01-18T17:29:42.040141Z","iopub.execute_input":"2022-01-18T17:29:42.040647Z","iopub.status.idle":"2022-01-18T17:33:10.602942Z","shell.execute_reply.started":"2022-01-18T17:29:42.040605Z","shell.execute_reply":"2022-01-18T17:33:10.602116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_CLASSES = 10\nLEARNING_RATE = 0.0001\nNUM_EPOCHS = 10\nBATCH_SIZE = 16\nINPUT_SHAPE = (224,224,3)\n\ndef compile_model(model, learning_rate):\n    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n                metrics=['accuracy'])\n    print(model.summary())\n    return model\n\n\ndef fit_model(model, initial_epochs, batch_size, train_data, train_labels):\n    history = model.fit(x = train_data, y = train_labels,\n                        epochs = initial_epochs, batch_size = batch_size,\n                        verbose = 1,validation_split=0.2)\n    return history\n\ndef plot_accuracy(history, model_name):\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n\n    plt.title(model_name+' Accuray')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    #plt.ylim([0.9,1])\n    plt.legend(['train','test'], loc='upper left')\n    plt.show()\n    \ndef plot_loss(history, model_name):\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n\n    plt.title(model_name+' Loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    #plt.ylim([0,.4])\n    plt.legend(['train','test'], loc='upper left')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-18T17:33:10.605201Z","iopub.execute_input":"2022-01-18T17:33:10.605641Z","iopub.status.idle":"2022-01-18T17:33:10.616021Z","shell.execute_reply.started":"2022-01-18T17:33:10.605601Z","shell.execute_reply":"2022-01-18T17:33:10.615271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TRANSFER LEARNING\nNow, we build models using transfer learning approaches to improve results.","metadata":{}},{"cell_type":"code","source":"def vgg(input_shape, num_classes, mode):\n    vgg = VGG16(\n        include_top=False, weights='imagenet', input_tensor=None,\n        input_shape=input_shape, pooling=None, classes=num_classes,\n        classifier_activation='softmax'\n        )\n    if mode=='feature-extraction':\n        vgg.trainable = False\n    if mode=='fine-tune':\n        vgg.trainable = True\n        # Let's take a look to see how many layers are in the base model\n        print(\"Number of layers in the base model: \", len(vgg.layers))\n\n        # Fine-tune from this layer onwards\n        fine_tune_at = 16\n\n        # Freeze all the layers before the `fine_tune_at` layer\n        for layer in vgg.layers[:fine_tune_at]:\n            layer.trainable =  False\n    print(vgg.summary())\n    return vgg","metadata":{"execution":{"iopub.status.busy":"2022-01-18T17:33:10.617212Z","iopub.execute_input":"2022-01-18T17:33:10.617562Z","iopub.status.idle":"2022-01-18T17:33:10.629766Z","shell.execute_reply.started":"2022-01-18T17:33:10.617524Z","shell.execute_reply":"2022-01-18T17:33:10.62903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transfer_learn(base_model, input_shape, num_classes):\n    inputs = tf.keras.Input(shape=input_shape)\n    x = preprocess_input(inputs)\n    x = base_model(x, training=False)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n    outputs = tf.keras.layers.Dense(num_classes)(x)\n    model = tf.keras.Model(inputs, outputs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-18T17:33:10.631143Z","iopub.execute_input":"2022-01-18T17:33:10.631414Z","iopub.status.idle":"2022-01-18T17:33:10.639763Z","shell.execute_reply.started":"2022-01-18T17:33:10.631378Z","shell.execute_reply":"2022-01-18T17:33:10.638986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Extraction\nExtracting bottleneck features from a pretrained VGG16","metadata":{}},{"cell_type":"code","source":"vgg16 = vgg(INPUT_SHAPE, NUM_CLASSES, 'feature-extraction')\nfe_model = compile_model(transfer_learn(vgg16, INPUT_SHAPE, NUM_CLASSES), LEARNING_RATE)\nfe_history = fit_model(fe_model, NUM_EPOCHS, BATCH_SIZE, X_Train, Y_Train)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T16:58:13.825198Z","iopub.execute_input":"2022-01-18T16:58:13.825882Z","iopub.status.idle":"2022-01-18T17:06:37.444567Z","shell.execute_reply.started":"2022-01-18T16:58:13.825845Z","shell.execute_reply":"2022-01-18T17:06:37.443807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(fe_history, 'Feature-Extraction')\nplot_accuracy(fe_history, 'Feature-Extraction')","metadata":{"execution":{"iopub.status.busy":"2022-01-18T17:06:37.449424Z","iopub.execute_input":"2022-01-18T17:06:37.451492Z","iopub.status.idle":"2022-01-18T17:06:37.879908Z","shell.execute_reply.started":"2022-01-18T17:06:37.451453Z","shell.execute_reply":"2022-01-18T17:06:37.879161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_acc = fe_model.evaluate(X_Test, Y_Test, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T17:06:37.881193Z","iopub.execute_input":"2022-01-18T17:06:37.881668Z","iopub.status.idle":"2022-01-18T17:06:47.185048Z","shell.execute_reply.started":"2022-01-18T17:06:37.881623Z","shell.execute_reply":"2022-01-18T17:06:47.184358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fine Tuning\nFine tune some layers of the VGG16 i.e. retrain some the weights of the top layers of the pre-trained model alongside the training of the top that we previously trained to increase performance even further.","metadata":{}},{"cell_type":"code","source":"fine_tune_epochs = 5\ntotal_epochs =  NUM_EPOCHS + fine_tune_epochs\nvgg16_fine = vgg(INPUT_SHAPE, NUM_CLASSES, 'fine-tune')\nfine_model = compile_model(transfer_learn(vgg16_fine, INPUT_SHAPE, NUM_CLASSES), LEARNING_RATE)\nft_history = fit_model(fine_model, total_epochs, BATCH_SIZE, X_Train, Y_Train)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T17:33:10.640913Z","iopub.execute_input":"2022-01-18T17:33:10.641256Z","iopub.status.idle":"2022-01-18T17:43:21.154669Z","shell.execute_reply.started":"2022-01-18T17:33:10.64122Z","shell.execute_reply":"2022-01-18T17:43:21.153866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(ft_history, 'Fine-Tuner')\nplot_accuracy(ft_history, 'Fine-Tuner')","metadata":{"execution":{"iopub.status.busy":"2022-01-18T17:43:21.157287Z","iopub.execute_input":"2022-01-18T17:43:21.15753Z","iopub.status.idle":"2022-01-18T17:43:21.576871Z","shell.execute_reply.started":"2022-01-18T17:43:21.157502Z","shell.execute_reply":"2022-01-18T17:43:21.57617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_acc = fine_model.evaluate(X_Test, Y_Test, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T17:43:21.578309Z","iopub.execute_input":"2022-01-18T17:43:21.578806Z","iopub.status.idle":"2022-01-18T17:43:42.528136Z","shell.execute_reply.started":"2022-01-18T17:43:21.578766Z","shell.execute_reply":"2022-01-18T17:43:42.527292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}